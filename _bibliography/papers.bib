---
---

@string{aps = {American Physical Society,}}

@article{JSMoCo,
  title={JSMoCo: Joint Coil Sensitivity and Motion Correction in Parallel MRI with a Self-Calibrating Score-Based Diffusion Model},
  author={Lixuan Chen and Xuanyu Tian and Jiangjie Wu and Ruimin Feng and Guoyan Lao and Yuyao Zhang and Hongjiang Wei},
  abstract={Magnetic Resonance Imaging (MRI) stands as a powerful modality in clinical diagnosis. However, it is known that MRI faces challenges such as long acquisition time and vulnerability to motion-induced artifacts. Despite the success of many existing motion correction algorithms, there has been limited research focused on correcting motion artifacts on the estimated coil sensitivity maps for fast MRI reconstruction. Existing methods might suffer from severe performance degradation due to error propagation resulting from the inaccurate coil sensitivity maps estimation. In this work, we propose to jointly estimate the motion parameters and coil sensitivity maps for under-sampled MRI reconstruction, referred to as JSMoCo. However, joint estimation of motion parameters and coil sensitivities results in a highly ill-posed inverse problem due to an increased number of unknowns. To address this, we introduce score-based diffusion models as powerful priors and leverage the MRI physical principles to efficiently constrain the solution space for this optimization problem. Specifically, we parameterize the rigid motion as three trainable variables and model coil sensitivity maps as polynomial functions. Leveraging the physical knowledge, we then employ Gibbs sampler for joint estimation, ensuring system consistency between sensitivity maps and desired images, avoiding error propagation from pre-estimated sensitivity maps to the reconstructed images. We conduct comprehensive experiments to evaluate the performance of JSMoCo on the fastMRI dataset. The results show that our method is capable of reconstructing high-quality MRI images from sparsely-sampled k-space data, even affected by motion. It achieves this by accurately estimating both motion parameters and coil sensitivities, effectively mitigating motion-related challenges during MRI reconstruction.},
  journal={IEEE Transactions on Medical Imaging},
  pdf={https://arxiv.org/abs/2310.09625},
  year={2023},
  abbr={IEEE TMI},
  state = "(under review)",
  preview={JSMoCo.png},
  selected={true},
}



@inproceedings{9761507,
  abbr={IEEE ISBI 2023},
  title={ASSURED: A Self-supervised Deep Decoder Network for Fetus Brain MRI Reconstruction},
  author={Wu, Jiangjie and Chen, Lixuan and Li, Zhenghao and Wang, Rongpin and Wei, Hongjiang and Zhang, Yuyao},
  abstract={High-resolution Magnetic Resonance Imaging (MRI) volume reconstruction from multiple arbitrary orientation motion-corrupted 2D slices is crucial for fetal brain MRI studies. Currently, most existing methods follow two-step approaches that iteratively perform slice to volume registration (SVR) and super-resolution reconstruction (SRR). However, the 3D volume reconstruction is often corrupted due to slice misalignment and brain anatomy blurring caused by severe motion during MR data collection, making the quantification challenging. To tackle these issues, we propose a novel learning-based self-supervised volume reconstruction technique that is robust to slice misalignment and motion artifacts. Specially, we combine a comprehensive forward model to present the complex image degradation process and an under-parameterized deep decoder structure to reduce the network overfitting with image artifacts caused by slice misalignment and motion. This methodology requires only one coarse SVR step in the whole reconstruction process and does not need any training dataset in SRR. We evaluated the performance of our technique on simulated MRI from brain atlas and on real clinical scanning fetus MR data. Experimental results demonstrated that the proposed approach achieved superior fetus brain reconstruction results compared with state-of-the-art methods},
  booktitle={20th IEEE International Symposium on Biomedical Imaging},  
  pdf={https://ieeexplore.ieee.org/abstract/document/10230366},
  year={2023},
  selected={true},
  preview={ISBI2023.png},
}

@InProceedings{10.1007/978-3-031-16446-0_1,
  abbr={IEEE TMI},
  author="Wu, Jiangjie and Chen, Lixuan and Li, Zhenghao and Wang, Rongpin and Wei, Hongjiang and Zhang, Yuyao",
  title="SUFFICIENT: A scan-specific unsupervised deep learning framework for high-resolution 3D isotropic fetal brain MRI reconstruction",
  booktitle="IEEE Transactions on Medical Imaging",
  year={2023},
  state = "(major revision)",
  abstract="High-resolution (HR) 3D fetal brain magnetic resonance imaging (MRI) volume reconstruction from multiple motion-corrupted stacks of 2D thick slices is crucial for clinical diagnosis and quantitative analysis. Reliable sliceto-volume registration (SVR)-based motion correction and super-resolution reconstruction (SRR) methods are essential for high-quality isotropic volume reconstruction. Deep learning (DL) has demonstrated potential in enhancing motion correction and SRR when compared to conventional methods. However, current supervised DL methods for SVR and SRR require external large-scale training datasets, which are difficult to obtain in clinical fetal MRI settings. To address these issues, we propose an unsupervised iterative SVR-SRR framework for isotropic HR volume reconstruction without using external databases. Specifically, we formulate the SVR process as a function that maps a thick 2D input slice and a target 3D volume to a rigid transformation matrix, which aligns the slice to the underlying location in the target volume. The function is parameterized by a convolutional neural network, which is trained by minimizing the difference between the volume slicing at the predicted position and the input slice. For the SRR process, we utilize a decoding network possessing a deep image prior framework with a comprehensive image degradation model to generate the HR volume. The decoding network, utilizing a forward degradation model, offers a local consistency prior to guide the reconstruction of HR volumes from input slices of individual subjects. Comprehensive experiments conducted on large-magnitude motion-corrupted simulation data and clinical data demonstrate the superior performance of the proposed framework over state-of-theart fetal brain reconstruction frameworks.",
  selected={true},
  preview={MICCAI_2023.jpeg},
}

@article{NeuroImage,
  abbr={IEEE TMI},
  author="Chen, Lixuan and Wu, Jiangjie and Wu, Qing and Lao, Guoyan and Wei, Hongjiang and Zhang, Yuyao",
  title="COLLATOR: Consistent Spatial-Temporal Longitudinal Atlas Construction via Implicit Neural Representation",
  journal = {IEEE Transactions on Medical Imaging},
  year={2023},
  state = {(under review)},
  abstract="Longitudinal brain atlases are essential tools for studying brain development. However, existing atlases often suffer from temporal inconsistency, due to the typical atlas construction method that averages brain images on discrete time points independently. Additionally, the differences in onto-genetic trends among samples at different time points further compound this issue. These inconsistencies may significantly impact the accuracy of brain developmental characteristic analysis. In this paper, we propose a multi-stage deep-learning framework to address this issue by treating it as a 4D image denoising task, where the 4D data consists of 3D brain volumes and 1D age. Our framework employs implicit neural representation to construct a continuous and noise-free longitudinal brain atlas as a function of the 4D spatial-temporal coordinate. We evaluate our approach on two modalities of brain atlases (QSM and fetus atlases) and show that our method significantly improves temporal consistency while maintaining accurate representation of brain structures. Furthermore, the continuous functions generated by our method can be used to generate 4D atlases with higher spatial and temporal resolution.",
  selected={true},
  preview={NueroImage.gif},
}

@inproceedings{chen2022continuous,
  abbr={MICCAI workshop},
  highlight={Oral},
  title={Continuous longitudinal fetus brain atlas construction via implicit neural representation},
  author={Chen, Lixuan and Wu, Jiangjie and Wu, Qing and Wei, Hongjiang and Zhang, Yuyao},
  abstract={Longitudinal fetal brain atlas is a powerful tool for understanding and characterizing the complex process of fetus brain development. Existing fetus brain atlases are typically constructed by averaged brain images on discrete time points independently over time. Due to the differences in onto-genetic trends among samples at different time points, the resulting atlases suffer from temporal inconsistency, which may lead to estimating error of the brain developmental characteristic parameters along the timeline. To this end, we proposed a multi-stage deep-learning framework to tackle the time inconsistency issue as a 4D (3D brain volume + 1D age) image data denoising task. Using implicit neural representation, we construct a continuous and noise-free longitudinal fetus brain atlas as a function of the 4D spatial-temporal coordinate. Experimental results on two public fetal brain atlases (CRL and FBA-Chinese atlases) show that the proposed method can significantly improve the atlas temporal consistency while maintaining good fetus brain structure representation. In addition, the continuous longitudinal fetus brain atlases can also be extensively applied to generate finer 4D atlases in both spatial and temporal resolution.},
  booktitle={International Workshop on Preterm, Perinatal and Paediatric Image Analysis},
  pages={38--47},
  year={2022},
  organization={Springer},
  pdf={https://link.springer.com/chapter/10.1007/978-3-031-17117-8_4},
  selected={true},
  preview="MICCAI_workshop_PIPPI.jpeg",
  award={Best Paper Honorable Mention},
}

@article{wu2021age,
  title={Age-specific structural fetal brain atlases construction and cortical development quantification for Chinese population},
  author={Wu, Jiangjie and Sun, Taotao and Yu, Boliang and Li, Zhenghao and Wu, Qing and Wang, Yutong and Qian, Zhaoxia and Zhang, Yuyao and Jiang, Ling and Wei, Hongjiang},
  journal={Neuroimage},
  volume={241},
  pages={118412},
  year={2021},
  publisher={Elsevier},
  pdf={https://www.sciencedirect.com/science/article/pii/S105381192100687X},
    selected={true},
    preview="MICCAI_workshop_PIPPI.jpeg",
}

@inproceedings{wu2021longitudinal,
  title={Longitudinal Chinese population structural fetal brain atlases construction: toward precise fetal brain segmentation},
  author={Wu, Jiangjie and Yu, Boliang and Wang, Lihui and Yang, Qing and Zhang, Yuyao},
  booktitle={2021 43rd Annual International Conference of the IEEE Engineering in Medicine \& Biology Society (EMBC)},
  pages={2745--2749},
  year={2021},
  organization={IEEE},
  pdf={https://ieeexplore.ieee.org/abstract/document/9630514},
    selected={true},
    preview="MICCAI_workshop_PIPPI.jpeg",
}