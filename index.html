<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Jiangjie Wu</title> <meta name="author" content="Jiangjie Wu"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/button.jpeg"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://miraiwu.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching</a> </li> <li class="nav-item "> <a class="nav-link" href="/friend/">Friends</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Jiangjie</span> Wu </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <img src="/assets/img/wujj.JPG" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="wujj.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <p>I am Jiangjie Wu (吴江杰 in Chinese), a 4th-year Ph.D student in <a href="https://smilelab.com.cn/" target="_blank" rel="noopener noreferrer">SMILE Lab<img class="emoji" title=":smiley:" alt=":smiley:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f603.png" height="20" width="20"></a> at <a href="https://www.shanghaitech.edu.cn/eng/" target="_blank" rel="noopener noreferrer">ShanghaiTech University</a> (Shanghai, China), advised by Prof. <a href="https://sist.shanghaitech.edu.cn/sist_en/2020/0814/c7582a54827/page.htm" target="_blank" rel="noopener noreferrer">Yuyao Zhang</a>. Before that, I received my B.E. degree at Yunnan University, Yunnan in 2021.</p> <p>I am interested in a variety of topics related to <strong>Fetal MRI</strong> and <strong>Model-based deep learning for inverse problems</strong>. My current research focuses include: <br></p> <ul> <li>Fetal MRI; <br> </li> <li>Motion Correction; <br> </li> <li>Super-resolution Reconstruction; <br> </li> <li>MRI Artifact Removal</li> <li>Model-based Deep Learning. <ul> <li>Deep Image Prior, Neural Representation, Diffusion Model</li> </ul> </li> </ul> <p>See more in the <a href="https://miraiwu.github.io/assets/pdf/wujj.pdf">detailed CV</a>.</p> <p><span style="color:#008fe0"><b>I am looking for a post-doc position for 2025 Fall!</b></span></p> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%77%75%6A%6A@%73%68%61%6E%67%68%61%69%74%65%68.%65%64%75.%63%6E" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/DSxjiWUAAAAJ" title="ORCID" target="_blank" rel="noopener noreferrer"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=DSxjiWUAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/miraiwu" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> </div> <div class="contact-note"> Feel free to find me in any way you like :) </div> </div> <div class="news"> <h2>news</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Mar 2, 2023</th> <td> Three paper accepted by IEEE ISBI <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Sep 18, 2022</th> <td> One paper accepted by MICCAI workshop PIPPI <strong><font color="red">(Best Paper Honorable Mention)</font></strong> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Jul 19, 2021</th> <td> One paper accepted by NeuroImage <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> </table> </div> </div> <div class="publications"> <h2>selected publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3 " style="text-align:center"> <abbr class="badge" style="background: var(--global-theme-color);border-style: solid;border-width: 2px;border-color:var(--global-theme-color)"> <div style="color:var(--global-bg-color);">IEEE TMI</div></abbr><br><p></p> <img id="JSMoCopng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/JSMoCo.png"><div id="JSMoCopng-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('JSMoCopng-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="JSMoCopng-modal-img"> </div> <script>var modal=document.getElementById("JSMoCopng-modal"),img=document.getElementById("JSMoCopng"),modalImg=document.getElementById("JSMoCopng-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="JSMoCo" class="col-sm-9"> <div class="title">JSMoCo: Joint Coil Sensitivity and Motion Correction in Parallel MRI with a Self-Calibrating Score-Based Diffusion Model</div> <div class="author"> Lixuan Chen , Xuanyu Tian , <em>Jiangjie Wu</em> , Ruimin Feng , Guoyan Lao , Yuyao Zhang , Hongjiang Wei</div> <div class="periodical"> <em>IEEE Transactions on Medical Imaging</em> (under review) </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2310.09625" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Magnetic Resonance Imaging (MRI) stands as a powerful modality in clinical diagnosis. However, it is known that MRI faces challenges such as long acquisition time and vulnerability to motion-induced artifacts. Despite the success of many existing motion correction algorithms, there has been limited research focused on correcting motion artifacts on the estimated coil sensitivity maps for fast MRI reconstruction. Existing methods might suffer from severe performance degradation due to error propagation resulting from the inaccurate coil sensitivity maps estimation. In this work, we propose to jointly estimate the motion parameters and coil sensitivity maps for under-sampled MRI reconstruction, referred to as JSMoCo. However, joint estimation of motion parameters and coil sensitivities results in a highly ill-posed inverse problem due to an increased number of unknowns. To address this, we introduce score-based diffusion models as powerful priors and leverage the MRI physical principles to efficiently constrain the solution space for this optimization problem. Specifically, we parameterize the rigid motion as three trainable variables and model coil sensitivity maps as polynomial functions. Leveraging the physical knowledge, we then employ Gibbs sampler for joint estimation, ensuring system consistency between sensitivity maps and desired images, avoiding error propagation from pre-estimated sensitivity maps to the reconstructed images. We conduct comprehensive experiments to evaluate the performance of JSMoCo on the fastMRI dataset. The results show that our method is capable of reconstructing high-quality MRI images from sparsely-sampled k-space data, even affected by motion. It achieves this by accurately estimating both motion parameters and coil sensitivities, effectively mitigating motion-related challenges during MRI reconstruction.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 " style="text-align:center"> <abbr class="badge" style="background: var(--global-theme-color);border-style: solid;border-width: 2px;border-color:var(--global-theme-color)"> <div style="color:var(--global-bg-color);">IEEE ISBI 2023</div></abbr><br><p></p> <img id="ISBI2023png" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/ISBI2023.png"><div id="ISBI2023png-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('ISBI2023png-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="ISBI2023png-modal-img"> </div> <script>var modal=document.getElementById("ISBI2023png-modal"),img=document.getElementById("ISBI2023png"),modalImg=document.getElementById("ISBI2023png-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="9761507" class="col-sm-9"> <div class="title">ASSURED: A Self-supervised Deep Decoder Network for Fetus Brain MRI Reconstruction</div> <div class="author"> <em>Jiangjie Wu</em> , Lixuan Chen , Zhenghao Li , Rongpin Wang , Hongjiang Wei , Yuyao Zhang</div> <div class="periodical"> <em> 20th IEEE International Symposium on Biomedical Imaging</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10230366" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>High-resolution Magnetic Resonance Imaging (MRI) volume reconstruction from multiple arbitrary orientation motion-corrupted 2D slices is crucial for fetal brain MRI studies. Currently, most existing methods follow two-step approaches that iteratively perform slice to volume registration (SVR) and super-resolution reconstruction (SRR). However, the 3D volume reconstruction is often corrupted due to slice misalignment and brain anatomy blurring caused by severe motion during MR data collection, making the quantification challenging. To tackle these issues, we propose a novel learning-based self-supervised volume reconstruction technique that is robust to slice misalignment and motion artifacts. Specially, we combine a comprehensive forward model to present the complex image degradation process and an under-parameterized deep decoder structure to reduce the network overfitting with image artifacts caused by slice misalignment and motion. This methodology requires only one coarse SVR step in the whole reconstruction process and does not need any training dataset in SRR. We evaluated the performance of our technique on simulated MRI from brain atlas and on real clinical scanning fetus MR data. Experimental results demonstrated that the proposed approach achieved superior fetus brain reconstruction results compared with state-of-the-art methods</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 " style="text-align:center"> <abbr class="badge" style="background: var(--global-theme-color);border-style: solid;border-width: 2px;border-color:var(--global-theme-color)"> <div style="color:var(--global-bg-color);">IEEE TMI</div></abbr><br><p></p> <img id="MICCAI_2023jpeg" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/MICCAI_2023.jpeg"><div id="MICCAI_2023jpeg-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('MICCAI_2023jpeg-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="MICCAI_2023jpeg-modal-img"> </div> <script>var modal=document.getElementById("MICCAI_2023jpeg-modal"),img=document.getElementById("MICCAI_2023jpeg"),modalImg=document.getElementById("MICCAI_2023jpeg-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="10.1007/978-3-031-16446-0_1" class="col-sm-9"> <div class="title">SUFFICIENT: A scan-specific unsupervised deep learning framework for high-resolution 3D isotropic fetal brain MRI reconstruction</div> <div class="author"> <em>Jiangjie Wu</em> , Lixuan Chen , Zhenghao Li , Rongpin Wang , Hongjiang Wei , Yuyao Zhang</div> <div class="periodical"> <em> IEEE Transactions on Medical Imaging</em> (major revision) </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>High-resolution (HR) 3D fetal brain magnetic resonance imaging (MRI) volume reconstruction from multiple motion-corrupted stacks of 2D thick slices is crucial for clinical diagnosis and quantitative analysis. Reliable sliceto-volume registration (SVR)-based motion correction and super-resolution reconstruction (SRR) methods are essential for high-quality isotropic volume reconstruction. Deep learning (DL) has demonstrated potential in enhancing motion correction and SRR when compared to conventional methods. However, current supervised DL methods for SVR and SRR require external large-scale training datasets, which are difficult to obtain in clinical fetal MRI settings. To address these issues, we propose an unsupervised iterative SVR-SRR framework for isotropic HR volume reconstruction without using external databases. Specifically, we formulate the SVR process as a function that maps a thick 2D input slice and a target 3D volume to a rigid transformation matrix, which aligns the slice to the underlying location in the target volume. The function is parameterized by a convolutional neural network, which is trained by minimizing the difference between the volume slicing at the predicted position and the input slice. For the SRR process, we utilize a decoding network possessing a deep image prior framework with a comprehensive image degradation model to generate the HR volume. The decoding network, utilizing a forward degradation model, offers a local consistency prior to guide the reconstruction of HR volumes from input slices of individual subjects. Comprehensive experiments conducted on large-magnitude motion-corrupted simulation data and clinical data demonstrate the superior performance of the proposed framework over state-of-theart fetal brain reconstruction frameworks.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 " style="text-align:center"> <abbr class="badge" style="background: var(--global-theme-color);border-style: solid;border-width: 2px;border-color:var(--global-theme-color)"> <div style="color:var(--global-bg-color);">IEEE TMI</div></abbr><br><p></p> <img id="NueroImagegif" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/NueroImage.gif"><div id="NueroImagegif-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('NueroImagegif-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="NueroImagegif-modal-img"> </div> <script>var modal=document.getElementById("NueroImagegif-modal"),img=document.getElementById("NueroImagegif"),modalImg=document.getElementById("NueroImagegif-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="NeuroImage" class="col-sm-9"> <div class="title">COLLATOR: Consistent Spatial-Temporal Longitudinal Atlas Construction via Implicit Neural Representation</div> <div class="author"> Lixuan Chen , <em>Jiangjie Wu</em> , Qing Wu , Guoyan Lao , Hongjiang Wei , Yuyao Zhang</div> <div class="periodical"> <em>IEEE Transactions on Medical Imaging</em> (under review) </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Longitudinal brain atlases are essential tools for studying brain development. However, existing atlases often suffer from temporal inconsistency, due to the typical atlas construction method that averages brain images on discrete time points independently. Additionally, the differences in onto-genetic trends among samples at different time points further compound this issue. These inconsistencies may significantly impact the accuracy of brain developmental characteristic analysis. In this paper, we propose a multi-stage deep-learning framework to address this issue by treating it as a 4D image denoising task, where the 4D data consists of 3D brain volumes and 1D age. Our framework employs implicit neural representation to construct a continuous and noise-free longitudinal brain atlas as a function of the 4D spatial-temporal coordinate. We evaluate our approach on two modalities of brain atlases (QSM and fetus atlases) and show that our method significantly improves temporal consistency while maintaining accurate representation of brain structures. Furthermore, the continuous functions generated by our method can be used to generate 4D atlases with higher spatial and temporal resolution.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 " style="text-align:center"> <abbr class="badge" style="background: var(--global-theme-color);border-style: solid;border-width: 2px;border-color:var(--global-theme-color)"> <div style="color:var(--global-bg-color);">MICCAI workshop</div></abbr><br><abbr class="badge" style="background: var(--global-bg-color);border-style: solid;border-width: 2px;border-color:var(--global-theme-color)"> <div style="color:var(--global-theme-color);">Oral</div></abbr><p></p> <img id="MICCAI_workshop_PIPPIjpeg" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/MICCAI_workshop_PIPPI.jpeg"><div id="MICCAI_workshop_PIPPIjpeg-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('MICCAI_workshop_PIPPIjpeg-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="MICCAI_workshop_PIPPIjpeg-modal-img"> </div> <script>var modal=document.getElementById("MICCAI_workshop_PIPPIjpeg-modal"),img=document.getElementById("MICCAI_workshop_PIPPIjpeg"),modalImg=document.getElementById("MICCAI_workshop_PIPPIjpeg-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="chen2022continuous" class="col-sm-9"> <div class="title">Continuous longitudinal fetus brain atlas construction via implicit neural representation</div> <div class="author"> Lixuan Chen , <em>Jiangjie Wu</em> , Qing Wu , Hongjiang Wei , Yuyao Zhang</div> <div style="color:red"><b>Best Paper Honorable Mention</b></div> <div class="periodical"> <em> International Workshop on Preterm, Perinatal and Paediatric Image Analysis</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-17117-8_4" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Longitudinal fetal brain atlas is a powerful tool for understanding and characterizing the complex process of fetus brain development. Existing fetus brain atlases are typically constructed by averaged brain images on discrete time points independently over time. Due to the differences in onto-genetic trends among samples at different time points, the resulting atlases suffer from temporal inconsistency, which may lead to estimating error of the brain developmental characteristic parameters along the timeline. To this end, we proposed a multi-stage deep-learning framework to tackle the time inconsistency issue as a 4D (3D brain volume + 1D age) image data denoising task. Using implicit neural representation, we construct a continuous and noise-free longitudinal fetus brain atlas as a function of the 4D spatial-temporal coordinate. Experimental results on two public fetal brain atlases (CRL and FBA-Chinese atlases) show that the proposed method can significantly improve the atlas temporal consistency while maintaining good fetus brain structure representation. In addition, the continuous longitudinal fetus brain atlases can also be extensively applied to generate finer 4D atlases in both spatial and temporal resolution.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 " style="text-align:center"> <br><p></p> <img id="age_specificJPG" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/age_specific.JPG"><div id="age_specificJPG-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('age_specificJPG-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="age_specificJPG-modal-img"> </div> <script>var modal=document.getElementById("age_specificJPG-modal"),img=document.getElementById("age_specificJPG"),modalImg=document.getElementById("age_specificJPG-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="wu2021age" class="col-sm-9"> <div class="title">Age-specific structural fetal brain atlases construction and cortical development quantification for Chinese population</div> <div class="author"> <em>Jiangjie Wu</em> , Taotao Sun , Boliang Yu , Zhenghao Li , Qing Wu , Yutong Wang , Zhaoxia Qian , Yuyao Zhang , Ling Jiang , Hongjiang Wei</div> <div class="periodical"> <em>Neuroimage</em> </div> <div class="links"> <a href="https://www.sciencedirect.com/science/article/pii/S105381192100687X" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 " style="text-align:center"> <br><p></p> <img id="EMBCJPG" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/EMBC.JPG"><div id="EMBCJPG-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('EMBCJPG-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="EMBCJPG-modal-img"> </div> <script>var modal=document.getElementById("EMBCJPG-modal"),img=document.getElementById("EMBCJPG"),modalImg=document.getElementById("EMBCJPG-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="wu2021longitudinal" class="col-sm-9"> <div class="title">Longitudinal Chinese population structural fetal brain atlases construction: toward precise fetal brain segmentation</div> <div class="author"> <em>Jiangjie Wu</em> , Boliang Yu , Lihui Wang , Qing Yang , Yuyao Zhang</div> <div class="periodical"> <em> 2021 43rd Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC)</em> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/abstract/document/9630514" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> </div> </div> </li> </ol> </div> <br> <div style="text-align: center;"> <div style="display:inline-block;width:70%;"> <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5g14zg1k2k0&amp;m=6&amp;c=007eff&amp;cr1=0006ff&amp;f=arial&amp;l=33" async="async"></script> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Jiangjie Wu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. Last updated: December 15, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>